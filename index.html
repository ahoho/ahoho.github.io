<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title>Alexander Hoyle's Homepage</title>
    <link rel="shortcut icon" href="assets/img/favicon.ico">
    <link rel="stylesheet" href="assets/css/simple.css">
</head>
<body>
    <div class="container">
        <div class="center">
        <h1>Alexander Miserlis Hoyle</h1>
        </div>
    </div>
    <div class="container">
        <ul class="links">
            <li><a href="/assets/pdf/cv.pdf" target="_blank">[Academic CV]</a></li>
            <li><a href="mailto:%68%6F%79%6C%65@%75%6D%64.%65%64%75/''">[Email]</a></li>
            <li><a href="https://scholar.google.com/citations?user=NpK0IXgAAAAJ">[Google Scholar]</a></li>
            <li><a href="https://www.semanticscholar.org/author/Alexander-Miserlis-Hoyle/49462969">[Semantic Scholar]</a></li>
            <li><a href="https://github.com/ahoho">[Github]</a></li>
            <li><a href="https://twitter.com/miserlis_">[Twitter]</a></li>
        </ul>
        </div>
    <hr>

    <div class="container">
        <div class="about">
        <p><img class="prof-pic" alt="Profile picture" src="assets/img/prof_pic.jpg">
        I'm a fifth-year PhD student working at the University of Maryland's <a href="https://wiki.umiacs.umd.edu/clip/index.php/Main_Page">Computational Linguistics and Information Processing</a> lab, where I'm advised by <a href="http://users.umiacs.umd.edu/~resnik/">Philip Resnik</a>.</p>
        
        <p>My research is oriented around the development and evaluation of methods for computational social science. My basic contention is that the field of NLP is well-served served by grounding it in the needs of social science&mdash;giving direction to concepts like interpretability and generalization. On the methods side, I'm interested in identifying latent constructs (perhaps call it "very abstractive summarization"): topic models, ideal points models, NLG for annotation. In terms of evaluation, I like to think about validity: are we really measuring what we want to measure? Topically, I'm drawn to work on bias &amp; fairness and political science; more recently, I've started work on constructs in mental health, specifically those relating to suicidality.</p>

        <p>Last summer I was an intern in the <a href="https://www.microsoft.com/en-us/research/theme/fate-montreal/">FATE group at Microsoft Research</a>. In the past I have interned with <a href="https://allenai.org/allennlp">AllenNLP at AI2</a>. Previously, I completed my master's in computational statistics and machine learning at University College London, where my thesis advisors were <a href="http://www.riedelcastro.org">Sebastian Riedel</a> and <a href="http://www.bris.ac.uk/expsych/people/jeffrey-j-mitchell/overview.html">Jeff Mitchell</a> at the <a href="https://nlp.cs.ucl.ac.uk/">UCL NLP</a> group.</p>
            
        <p>After undergrad, I was a Research Analyst at The Brattle Group in Cambridge, Massachusetts, where I built econometric models, developed a document retrieval platform, and did additional work that could be classified as data science. In a key project, I helped conduct research on New York City public housing for the U.S. Department of Justice; these efforts eventually led to a <a href="https://nypost.com/2018/06/11/city-settles-for-more-than-2b-with-nycha-over-horrendous-living-conditions/">$2.2 billion settlement</a> to improve conditions.</p>

        <p>You can reach me at <a href="mailto:%68%6F%79%6C%65@%75%6D%64.%65%64%75/''">hoyle [at] umd [dot] edu</a>. I use masculine pronouns.</p>
        </div>
    </div>
    <div class="container">
<h2>Publications</h2>
    <h3>2024</h3>
    <ul>
    <li>
        <span class="title">TopicGPT: A Prompt-based Topic Modeling Framework<br></span>
        <span class="author">
Chau Minh Pham, <b>Alexander Hoyle</b>, Simeng Sun and Mohit Iyyer.        </span>
        
        <span class="periodical">
            <em>In NAACL.</em>
          
            2024
        </span>
        <br>
            <span class="links">
                [<a href="https://arxiv.org/abs/2311.01449" target="_blank">Link</a>]
            <br>
            </span>
    </li>
    </ul>
    <h3>2023</h3>
    <ul>
    <li>
        <span class="title">Natural Language Decompositions of Implicit Content Enable Better Text Representations<br></span>
        <span class="author">
<b>Alexander Hoyle</b>, Rupak Sarkar, Pranav Goel and Philip Resnik.        </span>
        
        <span class="periodical">
            <em>In EMNLP.</em>
          
            2023
        </span>
        <br>
            <span class="links">
                [<a href="https://arxiv.org/abs/2305.14583" target="_blank">Link</a>]
            <br>
            </span>
    </li>
    <li>
        <span class="title">Re-visiting Automated Topic Model Evaluation with Large Language Models<br></span>
        <span class="author">
Dominik Stammbach, Vilém Zouhar, <b>Alexander Hoyle</b>, Mrinmaya Sachan and Elliott Ash.        </span>
        
        <span class="periodical">
            <em>In EMNLP.</em>
          
            2023
        </span>
        <br>
            <span class="links">
                [<a href="https://arxiv.org/abs/2305.12152" target="_blank">Link</a>]
            <br>
            </span>
    </li>
    </ul>
    <h3>2022</h3>
    <ul>
    <li>
        <span class="title">Are Neural Topic Models Broken?<br></span>
        <span class="author">
<b>Alexander Hoyle</b>, Pranav Goel, Rupak Sarkar and Philip Resnik.        </span>
        
        <span class="periodical">
            <em>In Findings of EMNLP.</em>
          
            2022
        </span>
        <br>
            <span class="links">
                [<a href="https://aclanthology.org/2022.findings-emnlp.390" target="_blank">Link</a>]
            <br>
            </span>
    </li>
    </ul>
    <h3>2021</h3>
    <ul>
    <li>
        <span class="title">Is Automated Topic Evaluation Broken? The Incoherence of Coherence<br></span>
        <span class="author">
<b>Alexander Hoyle</b>, Pranav Goel, Andrew Hian-Cheong, Denis Peskov, Jordan Boyd-Graber and Philip Resnik.        </span>
        
        <span class="periodical">
            <em>In NeurIPS (Spotlight Presentation).</em>
          
            2021
        </span>
        <br>
            <span class="links">
                [<a href="https://arxiv.org/abs/2107.02173" target="_blank">Link</a>]
            <br>
            </span>
    </li>
    <li>
        <span class="title">Evaluation Examples are not Equally Informative: How should that change NLP Leaderboards?<br></span>
        <span class="author">
Pedro Rodriguez, Joe Barrow, <b>Alexander Hoyle</b>, John P. Lalor, Robin Jia and Jordan Boyd-Graber.        </span>
        
        <span class="periodical">
            <em>In ACL.</em>
          
            2021
        </span>
        <br>
            <span class="links">
                [<a href="https://aclanthology.org/2021.acl-long.346/" target="_blank">Link</a>]
            <br>
            </span>
    </li>
    <li>
        <span class="title">Do You Walk the Walk, Talk the Talk, or Tweet the Tweet?: Ideal Points and What They Reveal About Congressional Behavior.<br></span>
        <span class="author">
SoRelle Wyckoff-Gaynor, Pranav Goel, <b>Alexander Hoyle</b>, Kris Miler and Philip Resnik.        </span>
        
        <span class="periodical">
            <em>In Annual Meeting of the American Political Science Association.</em>
          
            2021
        </span>
        <br>
            <span class="links">
            <br>
            </span>
    </li>
    <li>
        <span class="title">Promoting Graph Awareness in Linearized Graph-to-Text Generation<br></span>
        <span class="author">
<b>Alexander Hoyle</b>, Ana Marasović and Noah A. Smith.        </span>
        
        <span class="periodical">
            <em>In Findings of ACL.</em>
          
            2021
        </span>
        <br>
            <span class="links">
                [<a href="https://aclanthology.org/2021.findings-acl.82/" target="_blank">Link</a>]
            <br>
            </span>
    </li>
    </ul>
    <h3>2020</h3>
    <ul>
    <li>
        <span class="title">Improving Neural Topic Models using Knowledge Distillation<br></span>
        <span class="author">
<b>Alexander Hoyle</b>, Pranav Goel and Philip Resnik.        </span>
        
        <span class="periodical">
            <em>In EMNLP.</em>
          
            2020
        </span>
        <br>
            <span class="links">
                [<a href="https://www.aclweb.org/anthology/2020.emnlp-main.137" target="_blank">Link</a>]
            [<a href="https://slideslive.com/38939229/improving-neural-topic-models-with-knowledge-distillation" target="_blank">Video</a>]
            <br>
                <details>
                    <summary>Abstract</summary>
                    Topic models are often used to identify human-interpretable topics to help make sense of large document collections. We use knowledge distillation to combine the best attributes of probabilistic topic models and pretrained transformers. Our modular method can be straightforwardly applied with any neural topic model to improve topic quality, which we demonstrate using two models having disparate architectures, obtaining state-of-the-art topic coherence. We show that our adaptable framework not only improves performance in the aggregate over all estimated topics, as is commonly reported, but also in head-to-head comparisons of aligned topics.
                </details>
            </span>
    </li>
    </ul>
    <h3>2019</h3>
    <ul>
    <li>
        <span class="title">Combining Sentiment Lexica with a Multi-View Variational Autoencoder<br></span>
        <span class="author">
<b>Alexander Hoyle</b>, Lawrence Wolf-Sonkin, Hanna Wallach, Ryan Cotterell and Isabelle Augenstein.        </span>
        
        <span class="periodical">
            <em>In NAACL.</em>
          
            2019
        </span>
        <br>
            <span class="links">
                [<a href="https://www.aclweb.org/anthology/N19-1065" target="_blank">Link</a>]
                [<a href="/assets/pdf/SentiVAE.pdf" target="_blank">Slides</a>]
            <br>
                <details>
                    <summary>Abstract</summary>
                    When assigning quantitative labels to a dataset, different methodologies may rely on different scales. In particular, when assigning polarities to words in a sentiment lexicon, annotators may use binary, categorical, or continuous labels. Naturally, it is of interest to unify these labels from disparate scales to both achieve maximal coverage over words and to create a single, more robust sentiment lexicon while retaining scale coherence. We introduce a generative model of sentiment lexica to combine disparate scales into a common latent representation. We realize this model with a novel multi-view variational autoencoder (VAE), called SentiVAE. We evaluate our approach via a downstream text classification task involving nine English-Language sentiment analysis datasets; our representation outperforms six individual sentiment lexica, as well as a straightforward combination thereof.
                </details>
            </span>
    </li>
    <li>
        <span class="title">Unsupervised Discovery of Gendered Language through Latent-Variable Modeling<br></span>
        <span class="author">
<b>Alexander Hoyle</b>, Lawrence Wolf-Sonkin, Hanna Wallach, Isabelle Augenstein and Ryan Cotterell.        </span>
        
        <span class="periodical">
            <em>In ACL.</em>
          
            2019
        </span>
        <br>
            <span class="links">
                [<a href="https://www.aclweb.org/anthology/P19-1167" target="_blank">Link</a>]
                [<a href="/assets/pdf/Gendered-Words.pdf" target="_blank">Slides</a>]
            <br>
                <details>
                    <summary>Abstract</summary>
                    Studying the ways in which language is gendered has long been an area of interest in sociolinguistics. Studies have explored, for example, the speech of male and female characters in film and the language used to describe male and female politicians. In this paper, we aim not to merely study this phenomenon qualitatively, but instead to quantify the degree to which the language used to describe men and women is different and, moreover, different in a positive or negative way. To that end, we introduce a generative latent-variable model that jointly represents adjective (or verb) choice, with its sentiment, given the natural gender of a head (or dependent) noun. We find that there are significant differences between descriptions of male and female nouns and that these differences align with common gender stereotypes: Positive adjectives used to describe women are more often related to their bodies than adjectives used to describe men.
                </details>
            </span>
    </li>
    </ul>
    <h3>2018</h3>
    <ul>
    <li>
        <span class="title">Citation Detected: Automated Claim Detection through Natural Language Processing<br></span>
        <span class="author">
<b>Alexander Hoyle</b>.        </span>
        
        <span class="periodical">
            <em>University College London</em>, Master's Thesis.</em>
          
            2018
        </span>
        <br>
            <span class="links">
            <br>
            </span>
    </li>
    </ul>

    </div>

    <div class = "container">
        <h2>Service, Interests</h2>
        <ul>
            <li>I'm involved in graduate labor advocacy and organizing. I chair the Data and Research group of the Graduate Assistant Advisory Committee; I've testified on behalf of graduate assistants before the Maryland state legislature.</li>
            <li>I've participated in Científico Latino's <a href="https://www.cientificolatino.com/gsmi">Graduate Student Mentorship Initiative</a> for two application cycles. Mentees have been accepted to the residency program at Meta AI and UCSD. If you are applying to schools, please reach out and I will be happy to read your materials.</li>
            <li>In my spare time, I like to read, run, cycle, and socialize.</li>
        </ul>
    </div>

</body>
</html>